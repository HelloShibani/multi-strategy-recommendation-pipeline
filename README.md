![Python Version](https://img.shields.io/badge/python-3.10-blue)  
![License](https://img.shields.io/badge/license-MIT-green)  
![Last Commit](https://img.shields.io/github/last-commit/HelloShibani/multi-strategy-recommendation-pipeline)  
![Repo Size](https://img.shields.io/github/repo-size/HelloShibani/multi-strategy-recommendation-pipeline)  

# ğŸ§  Modular & Explainable Product Recommendation Engine

A robust, hybrid recommendation engine that uses multiple strategiesâ€”collaborative filtering, product embeddings, and fallback logicâ€”to serve personalized product recommendations even in sparse data scenarios. Designed with explainability and real-world applicability in mind.

---

<details>
  <summary>ğŸ“‘ Table of Contents</summary>

  - [Project Overview](#-project-overview)
  - [Techniques Used](#-techniques-used)
  - [Evaluation Summary](#-evaluation-summary)
  - [Dataset](#-dataset)
  - [Repository Structure](#-repository-structure)
  - [How to Run](#-how-to-run)
  - [Summary](#-Summary Slide)
  - [Future Enhancements](#-future-enhancements)

</details>

---

## ğŸ“Œ Project Overview

This system addresses three core objectives:

- âœ… Deliver accurate, personalized recommendations for active users  
- ğŸ” Ensure robust fallback logic for sparse and cold-start users  
- ğŸ§¾ Provide explainability metadata to trace why a product was recommended  

Built for practical deployment and system transparency across diverse user personas.

---

## âš™ï¸ Techniques Used

| Strategy Type      | Method                                |
|--------------------|----------------------------------------|
| Personalized       | SVD, Item-Item Similarity, Node2Vec    |
| Fallback           | Co-Purchase, Co-Search, Category Popularity
|
| Evaluation         | Precision@5, Recall@5, F1@5, Hit@5     |
| Explainability     | Strategy tags + fallback trace logic   |

---

## ğŸ“Š Evaluation Summary

- ğŸ“Œ Evaluated on 500 diverse users (active + cold-start)
- âœ… Strategy layering increased user coverage
- ğŸ’¡ Revealed gap for cold-start user personalization (future roadmap)

| Strategy                        | F1@5   | User Count |
|----------------------------------|--------|-------------|
| âœ… Personalized via Embedding     | 0.0322 | 76          |
| ğŸ” Fallback (Co-Purchase, etc.)   | 0.0000 | 47          |Â¹

---

Â¹ *Fallback strategies returned recommendations but failed to match any ground-truth in evaluation, highlighting a gap in effectiveness for cold-start users.*


### ğŸ“Š Visual Insights  
Visuals generated in the notebook and stored under `/visuals/`:

- ğŸ“ˆ F1@5 by strategy type  
- ğŸ‘¥ Strategy-wise user coverage  
- ğŸ§© Strategy distribution pie chart 

---

## ğŸ—ƒï¸ Dataset

Filtered subset of Amazon Reviews dataset:

- **15,747** users  
- **2,142** products  
- **18,263** interactions (after filtering for helpfulness, recency, etc.)


ğŸ“¦ [Amazon Fine Food Reviews â€“ Kaggle](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews)

Due to file size constraints, the original dataset (`Reviews.csv`) is **not included** in this repository.

### How to Use
To run the full pipeline:

1. Download `Reviews.csv` from the [Kaggle link](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews)
2. Place the file inside the `/data/` folder
3. Run the notebook `product_recommender_analysis.ipynb` from start to end

ğŸ“Œ _The file `Reviews.csv` is excluded via `.gitignore` for repository cleanliness._


---

## ğŸ“‚ Repository Structure

```bash
.
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ IntelliRec+End+to+End+Product+Recommendation+Systemder_analysis.ipynb   # Core logic & evaluation
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ interaction_df.csv                   # Engine-ready filtered data
â”‚   â”œâ”€â”€ evaluation_results.csv               # Output metrics
â”‚   â””â”€â”€ Reviews.csv                          # Original reviews (sample)
â”œâ”€â”€ visuals/
â”‚   â”œâ”€â”€ strategy_f1_score.png
â”‚   â”œâ”€â”€ strategy_user_count.png
â”‚   â””â”€â”€ strategy_user_distribution_pie.png
â””â”€â”€ README.md

---

## ğŸš€ How to Run

```bash
# Clone the repo and navigate to the folder
git clone <repo_url>
cd recommendation-engine

# Install dependencies (adjust as needed)
pip install -r requirements.txt

# Run the core notebook
Open notebook/IntelliRec+End+to+End+Product+Recommendation+Systemder_analysis.ipynb

# Outputs
â†’ Recommendations per user with explainability  
â†’ Evaluation metrics and visualizations  
â†’ All results saved in /visuals and /data folders


## ğŸ“„ Summary Slide
For a quick visual overview of the system architecture, methods, and evaluation insights:

ğŸ“„ [View Project Summary Slide (PDF)](./Topline%20Summary%20-%20Recommendation%20System%20Evaluation.pdf)


```markdown
## ğŸ› ï¸ Future Enhancements

- ğŸ”„ Implement cross-product category relevance for more nuanced recall evaluation  
- ğŸ’¬ Integrate sentiment-based personalization for experienced users  
- â„ï¸ Strengthen cold-start recommendations via user intent clustering or onboarding forms  
- ğŸ“¦ Package engine into modular pipeline for any tabular recommendation dataset  



